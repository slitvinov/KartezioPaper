{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in\n",
    "Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/slitvinov/KartezioPaper/blob/master/main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJK45Nr8Uynz",
    "outputId": "88987f56-f119-4227-8e31-18c7e285a000"
   },
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/slitvinov/KartezioPaper czifile roifile simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtD98dzmdwBC",
    "outputId": "1ee897b4-46f9-4c42-c6e7-164bbed655e8"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "git clone --depth 1 https://github.com/slitvinov/KartezioPaper\n",
    "mv KartezioPaper/dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlJxf-7IZ09n",
    "outputId": "16575d58-9cde-41cd-e07d-f2c62b6775d7"
   },
   "outputs": [],
   "source": [
    "from nodes import registry\n",
    "from numba import jit\n",
    "from numena.image.basics import image_new\n",
    "from numena.image.basics import image_split\n",
    "from numena.image.drawing import fill_polygons_as_labels\n",
    "from numena.image.morphology import WatershedSkimage\n",
    "from numena.io.image import imread_color\n",
    "from numena.io.imagej import read_polygons_from_roi\n",
    "from numena.io.json import json_read\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "def _parse_one_graph(genome, graph_source):\n",
    "    next_indices = graph_source.copy()\n",
    "    output_tree = graph_source.copy()\n",
    "    while next_indices:\n",
    "        next_index = next_indices.pop()\n",
    "        if next_index < g.inputs:\n",
    "            continue\n",
    "        idx = next_index - g.inputs\n",
    "        function_index = genome[g.inputs + idx, 0]\n",
    "        arity = g.nodes[function_index].arity\n",
    "        next_connections = set(genome[g.inputs + idx, 1:1 + arity])\n",
    "        next_indices = next_indices.union(next_connections)\n",
    "        output_tree = output_tree.union(next_connections)\n",
    "    return sorted(output_tree)\n",
    "\n",
    "\n",
    "def parse_to_graphs(genome):\n",
    "    outputs = genome[g.out_idx:, :]\n",
    "    graphs_list = [_parse_one_graph(genome, {output[1]}) for output in outputs]\n",
    "    return graphs_list\n",
    "\n",
    "\n",
    "def _x_to_output_map(genome, graphs_list, x):\n",
    "    output_map = {i: x[i].copy() for i in range(g.inputs)}\n",
    "    for graph in graphs_list:\n",
    "        for node in graph:\n",
    "            if node < g.inputs:\n",
    "                continue\n",
    "            idx = node - g.inputs\n",
    "            function_index = genome[g.inputs + idx, 0]\n",
    "            arity = g.nodes[function_index].arity\n",
    "            connections = genome[g.inputs + idx, 1:1 + arity]\n",
    "            inputs = [output_map[c] for c in connections]\n",
    "            p = genome[g.inputs + idx, g.para_idx:]\n",
    "            output_map[node] = g.nodes[function_index].call(inputs, p)\n",
    "    return output_map\n",
    "\n",
    "\n",
    "def _parse_one(genome, graphs_list, x):\n",
    "    output_map = _x_to_output_map(genome, graphs_list, x)\n",
    "    return [\n",
    "        output_map[output_gene[1]] for output_gene in genome[g.out_idx:, :]\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse(genome, x):\n",
    "    all_y_pred = []\n",
    "    graphs = parse_to_graphs(genome)\n",
    "    for xi in x:\n",
    "        y_pred = _parse_one(genome, graphs, xi)\n",
    "        mask, markers, y_pred = g.wt.apply(y_pred[0],\n",
    "                                           markers=y_pred[1],\n",
    "                                           mask=y_pred[0] > 0)\n",
    "        all_y_pred.append(y_pred)\n",
    "    return all_y_pred\n",
    "\n",
    "\n",
    "def call1(y_true, y_pred):\n",
    "    scores = []\n",
    "    for yi_pred in y_pred:\n",
    "        score = 0.0\n",
    "        y_size = len(y_true)\n",
    "        for i in range(y_size):\n",
    "            score += call0(y_true[i].copy(), yi_pred[i])\n",
    "        scores.append(score / y_size)\n",
    "    return scores\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _label_overlap(x, y):\n",
    "    x = x.ravel()\n",
    "    y = y.ravel()\n",
    "    overlap = np.zeros((1 + x.max(), 1 + y.max()), dtype=np.uint)\n",
    "    for i in range(len(x)):\n",
    "        overlap[x[i], y[i]] += 1\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def _intersection_over_union(masks_true, masks_pred):\n",
    "    overlap = _label_overlap(masks_true, masks_pred)\n",
    "    n_pixels_pred = np.sum(overlap, axis=0, keepdims=True)\n",
    "    n_pixels_true = np.sum(overlap, axis=1, keepdims=True)\n",
    "    iou = overlap / (n_pixels_pred + n_pixels_true - overlap)\n",
    "    iou[np.isnan(iou)] = 0.0\n",
    "    return iou\n",
    "\n",
    "\n",
    "def call0(y_true, y_pred):\n",
    "    n_true = np.max(y_true[0])\n",
    "    n_pred = np.max(y_pred)\n",
    "    tp = 0\n",
    "    if n_pred > 0:\n",
    "        iou = _intersection_over_union(y_true[0], y_pred)[1:, 1:]\n",
    "        tp = true_positive0(iou)\n",
    "    fp = n_pred - tp\n",
    "    fn = n_true - tp\n",
    "    if tp == 0:\n",
    "        if n_true == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "    else:\n",
    "        return (fp + fn) / (tp + fp + fn)\n",
    "\n",
    "\n",
    "def true_positive0(iou):\n",
    "    n_min = min(iou.shape[0], iou.shape[1])\n",
    "    costs = -(iou >= g.th).astype(float) - iou / (2 * n_min)\n",
    "    true_ind, pred_ind = linear_sum_assignment(costs)\n",
    "    match_ok = iou[true_ind, pred_ind] >= g.th\n",
    "    return match_ok.sum()\n",
    "\n",
    "\n",
    "def mutate_connections(genome, idx, only_one):\n",
    "    new_connections = np.random.randint(g.inputs + idx, size=g.arity)\n",
    "    new_value = new_connections[only_one]\n",
    "    new_connections = genome[g.inputs + idx, 1:g.para_idx]\n",
    "    new_connections[only_one] = new_value\n",
    "    genome[g.inputs + idx, 1:g.para_idx] = new_connections\n",
    "\n",
    "\n",
    "def mutate_parameters1(genome, idx, only_one):\n",
    "    new_parameters = np.random.randint(g.max_val, size=g.parameters)\n",
    "    old_parameters = genome[g.inputs + idx, g.para_idx:]\n",
    "    old_parameters[only_one] = new_parameters[only_one]\n",
    "    new_parameters = old_parameters.copy()\n",
    "    genome[g.inputs + idx, g.para_idx:] = new_parameters\n",
    "\n",
    "\n",
    "def mutate1(genome):\n",
    "    sampling_indices = np.random.choice(g.sampling_range,\n",
    "                                        g.n_mutations,\n",
    "                                        replace=False)\n",
    "    sampling_indices = g.all_indices[sampling_indices]\n",
    "    for idx, mutation_parameter_index in sampling_indices:\n",
    "        if mutation_parameter_index == 0:\n",
    "            genome[g.inputs + idx, 0] = np.random.randint(len(g.nodes))\n",
    "        elif mutation_parameter_index <= g.arity:\n",
    "            connection_idx = mutation_parameter_index - 1\n",
    "            mutate_connections(genome, idx, only_one=connection_idx)\n",
    "        else:\n",
    "            parameter_idx = mutation_parameter_index - g.arity - 1\n",
    "            mutate_parameters1(genome, idx, only_one=parameter_idx)\n",
    "    for idx in range(g.outputs):\n",
    "        if random.random() < 0.2:\n",
    "            genome[g.out_idx + idx, 1] = np.random.randint(g.out_idx, size=1)\n",
    "    return genome\n",
    "\n",
    "\n",
    "class G:\n",
    "    pass\n",
    "\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "g = G()\n",
    "g.max_val = 256\n",
    "g._lambda = 5\n",
    "g.generations = 10\n",
    "g.wt = WatershedSkimage(use_dt=False, markers_distance=21, markers_area=None)\n",
    "g.nodes = [\n",
    "    registry.nodes.instantiate(name) for name in registry.nodes.list().keys()\n",
    "]\n",
    "g.inputs = 3\n",
    "g.n = 30\n",
    "g.outputs = 2\n",
    "g.arity = 2\n",
    "g.parameters = 2\n",
    "g.out_idx = g.inputs + g.n\n",
    "g.para_idx = 1 + g.arity\n",
    "g.w = 1 + g.arity + g.parameters\n",
    "g.h = g.inputs + g.n + g.outputs\n",
    "g.th = 0.5\n",
    "g.n_mutations = int(np.floor(0.15 * g.n * g.w))\n",
    "g.all_indices = np.indices((g.n, g.w))\n",
    "g.all_indices = np.vstack(\n",
    "    (g.all_indices[0].ravel(), g.all_indices[1].ravel())).T\n",
    "g.sampling_range = range(len(g.all_indices))\n",
    "g.individuals = [None] * (g._lambda + 1)\n",
    "g.fitness = np.zeros(g._lambda + 1)\n",
    "meta = json_read(\"dataset/META.json\")\n",
    "name = meta[\"name\"]\n",
    "label_name = meta[\"label_name\"]\n",
    "dataframe = pd.read_csv(\"dataset/dataset.csv\")\n",
    "dataframe_training = dataframe[dataframe[\"set\"] == \"training\"]\n",
    "dataframe_training.reset_index(inplace=True)\n",
    "x0 = []\n",
    "y0 = []\n",
    "for row in dataframe_training.itertuples():\n",
    "    filepath = os.path.join(\"dataset\", row.input)\n",
    "    image = imread_color(filepath, rgb=False)\n",
    "    x, shape = image_split(image), image.shape[:2]\n",
    "    x0.append(x)\n",
    "    label_mask = image_new(shape)\n",
    "    if str(row.label) != \"nan\":\n",
    "        filepath = os.path.join(\"dataset\", row.label)\n",
    "        polygons = read_polygons_from_roi(filepath)\n",
    "        fill_polygons_as_labels(label_mask, polygons)\n",
    "    y0.append([label_mask])\n",
    "for i in range(g._lambda + 1):\n",
    "    g.individuals[i] = np.zeros((g.h, g.w), dtype=np.uint8)\n",
    "    for j in range(g.n):\n",
    "        g.individuals[i][g.inputs + j, 0] = np.random.randint(len(g.nodes))\n",
    "        mutate_connections(g.individuals[i], j, None)\n",
    "        new_parameters = np.random.randint(g.max_val, size=g.parameters)\n",
    "        g.individuals[i][g.inputs + j, g.para_idx:] = new_parameters\n",
    "    for j in range(g.outputs):\n",
    "        g.individuals[i][g.out_idx + j, 1] = np.random.randint(g.out_idx,\n",
    "                                                               size=1)\n",
    "y_pred = []\n",
    "for i in range(len(g.individuals)):\n",
    "    y = parse(g.individuals[i], x0)\n",
    "    y_pred.append(y)\n",
    "g.fitness = call1(y0, y_pred)\n",
    "print(f\"{0:08} {g.fitness[0]:.16e}\")\n",
    "current_generation = 0\n",
    "while current_generation < g.generations:\n",
    "    i = np.argmin(g.fitness)\n",
    "    elite = g.individuals[i].copy()\n",
    "    for i in range(g._lambda + 1):\n",
    "        g.individuals[i] = elite.copy()\n",
    "    for i in range(1, g._lambda + 1):\n",
    "        active_nodes = parse_to_graphs(g.individuals[i])\n",
    "        while True:\n",
    "            g.individuals[i] = mutate1(g.individuals[i])\n",
    "            new_active_nodes = parse_to_graphs(g.individuals[i])\n",
    "            if active_nodes != new_active_nodes:\n",
    "                break\n",
    "    y_pred = []\n",
    "    for i in range(len(g.individuals)):\n",
    "        y = parse(g.individuals[i], x0)\n",
    "        y_pred.append(y)\n",
    "    g.fitness = call1(y0, y_pred)\n",
    "    current_generation += 1\n",
    "    print(f\"{current_generation:08} {g.fitness[0]:.16e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
